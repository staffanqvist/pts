{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "blueprint.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTRxpSlaczHY"
      },
      "source": [
        "# Create a synthetic version of your own CSV or DataFrame\n",
        "\n",
        "This blueprint utilizes Gretel's premium SDKs to create a synthetic version of your own data. Our SDKs create automatic data validators to help ensure the data generated has the same semantics as the source data. Additionally, the SDKs do autmoatic header clustering to help maintain statistical relations between columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEM6kjRsczHd",
        "outputId": "72c6a6d8-61c1-416f-ee59-406a2efba805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -U gretel-client gretel-synthetics pandas"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gretel-client in /usr/local/lib/python3.7/dist-packages (0.7.12)\n",
            "Requirement already up-to-date: gretel-synthetics in /usr/local/lib/python3.7/dist-packages (0.15.6)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied, skipping upgrade: faker==4.1.1 in /usr/local/lib/python3.7/dist-packages (from gretel-client) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from gretel-client) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tenacity==6.2.0 in /usr/local/lib/python3.7/dist-packages (from gretel-client) (6.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml==5.4.1 in /usr/local/lib/python3.7/dist-packages (from gretel-client) (5.4.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from gretel-client) (2.25.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm==4.45.0 in /usr/local/lib/python3.7/dist-packages (from gretel-client) (4.45.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-privacy==0.5.1 in /usr/local/lib/python3.7/dist-packages (from gretel-synthetics) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gretel-synthetics) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from gretel-synthetics) (0.1.91)\n",
            "Requirement already satisfied, skipping upgrade: loky==2.8.0 in /usr/local/lib/python3.7/dist-packages (from gretel-synthetics) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from faker==4.1.1->gretel-client) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.7/dist-packages (from smart-open<3,>=2.1.0->gretel-client) (1.17.67)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from tenacity==6.2.0->gretel-client) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.24.0->gretel-client) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.24.0->gretel-client) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.24.0->gretel-client) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.24.0->gretel-client) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy==0.5.1->gretel-synthetics) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy==0.5.1->gretel-synthetics) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy==0.5.1->gretel-synthetics) (0.1.6)\n",
            "Requirement already satisfied, skipping upgrade: mpmath in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy==0.5.1->gretel-synthetics) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle in /usr/local/lib/python3.7/dist-packages (from loky==2.8.0->gretel-synthetics) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->smart-open<3,>=2.1.0->gretel-client) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->smart-open<3,>=2.1.0->gretel-client) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.21.0,>=1.20.67 in /usr/local/lib/python3.7/dist-packages (from boto3->smart-open<3,>=2.1.0->gretel-client) (1.20.67)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ-TmAdwczHd",
        "outputId": "0473430d-493b-4651-9dad-0526cd8f5493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load your Gretel API key. You can acquire this from the Gretel Console \n",
        "# @ https://console.gretel.cloud\n",
        "\n",
        "import pandas as pd\n",
        "from gretel_client import get_cloud_client\n",
        "\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "client = get_cloud_client(prefix=\"api\", api_key=\"prompt\")\n",
        "client.install_packages()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter Gretel API key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO pkg_installers.py: Authenticating with package manager\n",
            "INFO pkg_installers.py: Installing packages (this might take a while)\n",
            "ERROR pkg_installers.py: /usr/bin/python3 -m pip --disable-pip-version-check install https://gretel-opt-prod-usw2.s3.amazonaws.com/priv/pip/gretel-helpers/0.8.2/gretel_helpers-0.8.2-py3-none-any.whl?AWSAccessKeyId=ASIARC2BUADHUP25SVOC&Signature=nDmIrmdSfIss0A%2Fd9klgGaTfEeo%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEKb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHMEUCIGs5nw9t4pwoe21H9lQJF9NPwIGDhsgvejvhPvxZSVrjAiEAiPjchApJ2NccNaYbDt2Gb7Sd75Lneva8qJZRhCMXIZAq3gEILxACGgwwNzQ3NjI2ODI1NzUiDNhV4%2BWnsGRgK1O8eCq7AaUOC3L5yHsN%2Bm6TK%2FKpi%2Fyre7yJ3EWPwPJDhUeIiWkhT2bhL7wmwlUs40BDSh11c%2BE86dhMxZWPG9JWhxr8t6YZ8WwmeFCrKhjnPm5tV9qYa%2FsvsS6Hm%2BdrHUgVgYnvcuZ4LeBdHwUPEwVggjsjFJTp32JWHXw8faDzWVbfJdGux79SWdGuI3tKInGD0kpQT%2BFR%2Ft2iBqLuEJITpOyRH4nvrFh5GE67A%2FI3IZA8YPB3M%2F60rS2d5CyFwFgw2%2BPPhAY64AE8nStvsBKr3nJVRIEu1j4kS9ZlP9mkYCPVIPo3%2BIAI0PwAU8xX3xPRNq5HUQ5JfOmBl1WghpXuI3VihbhjwwGN4xsEVtQcYMzsRMOwvE8eH%2Bs7VUcj1zhbJI9kstmWu7tUGSLxjTpIXC5GUHCdIFLVeS4R0BaeRH5Fbkj6W5rB%2F%2F5NcFWbqBFqMO%2BV5FUdwIfU85dS30r08PAiRBb%2BiaeWQTOk%2ByyYSvX5r57UxKQnzEiOI3wgiv%2B3V9NPHTigOPykhHXOzs01S9JpKHil%2FCL1mBeMys4Jj4XERFNTcUeKxw%3D%3D&Expires=1620312302\n",
            "ERROR pkg_installers.py: ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\n",
            "ERROR pkg_installers.py: \n",
            "INFO pkg_installers.py: Finished installing Gretel packages\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMg9nX6SczHe",
        "outputId": "2e086cd1-8b63-42ff-f111-96826641ecac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "# Load and preview dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataset_path = 'https://www.dropbox.com/s/ywppusa8h7oq1e5/SE1_2018.csv?dl=0'\n",
        "nrows = 10000  # We will use this later when generating data\n",
        "training_df = pd.read_csv(dataset_path, nrows=nrows)\n",
        "print(training_df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-410ac6dc3b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.dropbox.com/s/ywppusa8h7oq1e5/SE1_2018.csv?dl=0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m  \u001b[0;31m# We will use this later when generating data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtraining_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;31m# \"delimiter\" is the annoying corner case because we alias it to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;31m# \"sep\" before doing comparison to the dialect values later on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;31m# Thus, we need a flag to indicate that we need to \"override\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;31m# the comparison to dialect values by checking if default values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;31m# for BOTH \"delimiter\" and \"sep\" were provided.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mfp_or_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0;34m\"is > 1 char long, and the 'c' engine \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                     \u001b[0;34m\"does not support such separators\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 )\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m                 self.names = [\n\u001b[1;32m   2060\u001b[0m                     \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m                 ]\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4-E_F0qczHe"
      },
      "source": [
        "# Create the Gretel Synthtetics Training / Model Configuration\n",
        "#\n",
        "# Gretel now offers Configuration Templates that provide starting points for a variety\n",
        "# of training data characteristics.\n",
        "#\n",
        "# You may browse the options here: https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics\n",
        "#\n",
        "# The helper function below will fetch the configuration based on the filename *WITHOUT the file extension*\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint_dir = str(Path.cwd() / \"checkpoints-synthetics\")\n",
        "\n",
        "try:\n",
        "    from gretel_client import get_synthetics_config\n",
        "    \n",
        "    # NOTE: Replace the \"default\" param with any of the configuration filenames (minus extension)\n",
        "    #\n",
        "    # https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics\n",
        "    #\n",
        "    # example: get_synthetics_config(\"low-record-count\")\n",
        "\n",
        "    config_template = get_synthetics_config(\"default\")\n",
        "    print(f\"Loaded config: {config_template}\")\n",
        "except ImportError:\n",
        "    print(\"ERROR: Could not load remote template, using default params. Please ensure you have the latest gretel-client installed.\")\n",
        "    config_template = {\"epochs\": 100}\n",
        "    \n",
        "\n",
        "# Set or update any custom parameters here\n",
        " \n",
        "config_template[\"overwrite\"] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw77l2Vg8nWl"
      },
      "source": [
        "# Capture transient import errors in Google Colab\n",
        "\n",
        "try:\n",
        "    from gretel_helpers.synthetics import SyntheticDataBundle\n",
        "except FileNotFoundError:\n",
        "    from gretel_helpers.synthetics import SyntheticDataBundle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCW-JaiNczHf"
      },
      "source": [
        "# Create a Gretel Synthetic Data Bundle\n",
        "\n",
        "from gretel_helpers.synthetics import create_df, SyntheticDataBundle\n",
        "\n",
        "model = SyntheticDataBundle(\n",
        "    training_df=training_df,\n",
        "    delimiter=None, # if ``None``, it will try and automatically be detected, otherwise you can set it\n",
        "    auto_validate=True, # build record validators that learn per-column, these are used to ensure generated records have the same composition as the original\n",
        "    synthetic_config=config_template, # the config for Synthetics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshnGoobczHf"
      },
      "source": [
        "model.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocX625j-czHf"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPM-gaU6czHf"
      },
      "source": [
        "# num_lines: how many rows to generate\n",
        "# max_invalid: the number of rows that do not pass semantic validation, if this number is exceeded, training will\n",
        "# stop\n",
        "model.generate(num_lines=nrows, max_invalid=nrows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbB7vnisczHg"
      },
      "source": [
        "model.get_synthetic_df()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX8qsizqczHg"
      },
      "source": [
        "# Generate report that shows the statistical performance between the training and synthetic data\n",
        "import IPython\n",
        "\n",
        "report_path = './report.html'\n",
        "model.generate_report(report_path=report_path)\n",
        "IPython.display.HTML(filename=report_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWXis_7TczHg"
      },
      "source": [
        "# Optionally save your model\n",
        "\n",
        "model.save(\"my_model.tar.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srW1HBA-d3Mp"
      },
      "source": [
        "# Save synthetic dataframe locally and to a private Gretel project \n",
        "\n",
        "df = model.get_synthetic_df()\n",
        "df.to_csv('synthetic-data.csv', index=False)\n",
        "\n",
        "# Publish newly created synthetic data to a new private Gretel project \n",
        "project = client.get_project(display_name=\"Blueprint: Create Synthetic Data\", create=True)\n",
        "project.send_dataframe(df, detection_mode=\"all\")\n",
        "print(f\"View this project at: {project.get_console_url()}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}